# ğŸ›¡ï¸ LLM Risk Evaluation Agent
**Governance-Grade Financial Integrity Risk Classification System**

![Python](https://img.shields.io/badge/Python-3.12-blue) ![Streamlit](https://img.shields.io/badge/Streamlit-Cloud-red) ![Anthropic](https://img.shields.io/badge/LLM-Claude%20Haiku-orange) ![Docker](https://img.shields.io/badge/Docker-Ready-blue)

Production-grade LLM evaluation system combining structured policy governance, versioned prompt engineering, and drift monitoring for financial integrity risk classification.

**ğŸ”— Live Demo:** [llm-risk-agent.streamlit.app](https://llm-risk-agent.streamlit.app)

Built in 8 days â€¢ 300 gold cases â€¢ 150 drift cases â€¢ 3 prompt versions â€¢ 6 violation categories

---

## ğŸ¯ What This Project Proves

âœ… **Policy-driven architecture** â€” Taxonomy governance separated from inference engine  
âœ… **Prompt versioning** â€” Three versions with measurable recall differences on drift  
âœ… **Drift robustness** â€” v3 achieves zero high-severity FN on adversarial language patterns  
âœ… **Production thinking** â€” Fail-safe defaults, audit logging, deterministic inference  
âœ… **Trust & Safety alignment** â€” Recall prioritized over precision for safety-critical systems  

---

## ğŸ“ Architecture
```
An interactive system diagram is available in the Streamlit dashboard under the **Architecture** tab and as `architecture/architecture.html` in this repository.

This layered design separates governance, prompt logic, inference, evaluation, and observability into clearly defined system boundaries.

Policy Layer (governance)
  â””â”€â”€ reason_codes.json      â€” machine-readable violation taxonomy (v1.0)
  â””â”€â”€ policy.md              â€” human-readable governance framework
  â””â”€â”€ severity_rubric.md     â€” enforcement decision logic + edge cases

Prompt Layer (versioned)
  â””â”€â”€ v1_baseline            â€” flat classification
  â””â”€â”€ v2_hierarchical        â€” structured step-by-step reasoning
  â””â”€â”€ v3_high_recall         â€” recall-optimized, implicit signal detection

Agent Layer (inference)
  â””â”€â”€ src/llm_client.py      â€” provider-flexible wrapper (Anthropic/OpenAI)
  â””â”€â”€ src/prompt_builder.py  â€” generic template loader
  â””â”€â”€ src/agent.py           â€” classification engine, fail-safe fallback

Evaluation Layer (metrics)
  â””â”€â”€ src/evaluator.py       â€” batch evaluation, per-case results
  â””â”€â”€ src/metrics_logger.py  â€” persistent audit log (timestamp, model, provider)

Dashboard Layer (observability)
  â””â”€â”€ app.py                 â€” 5-tab Streamlit dashboard
```

---

## ğŸ“Š Key Results

### Gold Dataset (300 cases â€” clean language)

| Version | Precision | Recall | F1 | HS Recall | Parse Errors |
|---|---|---|---|---|---|
| v1_baseline | 1.000 | 0.950 | 0.974 | 1.000 | 0 |
| **v2_hierarchical** | **1.000** | **0.967** | **0.983** | **1.000** | 0 |
| v3_high_recall | 1.000 | 0.950 | 0.974 | 1.000 | 0 |

All prompt versions achieve zero high-severity false negatives on clean data.  
**v2_hierarchical** delivers the highest overall recall and F1 on the gold dataset.

### Drift Dataset (150 cases â€” adversarial language patterns)

| Version | Recall | F1 | HS Recall | HS FN Count | Recall Drop |
|---|---|---|---|---|---|
| v1_baseline | 0.600 | 0.750 | 0.700 | 36 | 0.350 |
| v2_hierarchical | 0.800 | 0.889 | 0.950 | 6 | 0.167 |
| **v3_high_recall** | **0.840** | **0.913** | **1.000** | **0** | **0.104** |

**Key Finding:**  
On clean data, all versions perform strongly with minimal variance. Under adversarial drift, performance diverges materially â€” v1 misses 36 high-severity violations while v3 misses zero. This demonstrates that structured, recall-biased prompt engineering materially improves safety robustness under real-world language mutation.

---

## ğŸ—‚ï¸ Five-Level Taxonomy

| Level | Element | Example |
|---|---|---|
| 1 | Domain | Financial Integrity |
| 2 | Category | Investment Scam |
| 3 | Violation | Guaranteed Return |
| 4 | Severity | High |
| 5 | Enforcement | Remove |

**6 categories â€” 11 violation patterns â€” 3 severity levels â€” 3 enforcement actions**

| Category | Violations |
|---|---|
| Investment Scam | GUARANTEED_RETURN, URGENCY_PRESSURE, FAKE_PROFIT_EVIDENCE |
| Impersonation Scam | CELEBRITY_IMPERSONATION, FAKE_INSTITUTION |
| Contact Redirection | OFF_PLATFORM_MOVE |
| Crypto Pump & Dump | PUMP_SIGNAL, UNDISCLOSED_PROMOTION |
| Loan Fraud | FAKE_LOAN_OFFER |
| Job Offer Scam | FAKE_JOB_OFFER, MONEY_MULE_RECRUITMENT |

---

## ğŸ§ª Datasets

| Dataset | Cases | Composition |
|---|---|---|
| Gold | 300 | 60% violations (180), 40% benign (120) |
| Drift | 150 | 5 drift types Ã— 30 cases each |

**Drift types:**
- **Slang Mutation** â€” Gen-Z phrasing ("no cap", "fr fr", "bussin")
- **Emoji Obfuscation** â€” Character substitution (GğŸ”’uaranteed, r3turns)
- **Indirect Phrasing** â€” Implicit guaranteed return claims
- **Encoded Language** â€” Coordinated pump signals without explicit keywords
- **Subtle Medium Drift** â€” Off-platform redirection without platform names

---

## ğŸ› ï¸ Technical Highlights

### 1. Fail Safe, Not Fail Open
```python
# Parse errors escalate â€” never silently allow
PARSE_ERROR_DEFAULT = {
    "label": 1,
    "violation": "PARSE_ERROR",
    "severity": "medium",
    "enforcement": "escalate_review",
    "rationale": "Model output parsing failed â€” escalated for safety."
}
```

### 2. Provider-Flexible LLM Client
```python
# Switch providers by changing one environment variable
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "anthropic")
LLM_MODEL = os.getenv("LLM_MODEL", "claude-haiku-4-5-20251001")
```

### 3. Retry with Exponential Backoff
```python
# Handles API overload gracefully
if any(term in str(e).lower() for term in ["overloaded", "rate", "429", "529"]):
    wait_time = 2 ** attempt
    time.sleep(wait_time)
```

### 4. Recall-Biased Prompt Design
```
PRIMARY OBJECTIVE:
When uncertain between allow and escalate_review â†’ choose escalate_review.
When uncertain between medium and high â†’ choose high.
```

---

## ğŸ”§ Key Engineering Decisions

| Challenge | Decision | Rationale |
|---|---|---|
| LLM output hallucinating violation codes | Explicit enum constraints in all prompts | Prevents downstream schema mismatch |
| Parse failure defaulting to benign | Sentinel key `_parse_error` â†’ escalate | Fail safe in safety systems |
| API overload on 900 sequential calls | Exponential backoff + 300ms throttle | Production-style resilience |
| `.format()` crashing on JSON examples | Escape curly braces as `{{}}` | Python string formatting edge case |
| Drift recall collapsing on v1 | Implicit signal detection in v3 | Slang/emoji bypass flat keyword matching |

---

## ğŸ“ˆ Trade-offs & Limitations

**What's Strong**  
âœ… Zero high-severity FN on drift (v3)  
âœ… Clean policy/prompt separation  
âœ… Audit-ready evaluation logs  
âœ… Production-safe failure defaults  
âœ… Deterministic inference (temperature=0)  

**Production Considerations**  
âŒ Synthetic dataset â€” real-world performance will differ  
âŒ English-language only â€” no multilingual support  
âŒ No adversarial defense mechanisms  
âŒ Single domain â€” multi-domain extension not implemented  
âŒ Static prompts â€” no online prompt tuning  

---

## ğŸ¤ Talking Points

**"Walk me through your project"**  
"I built a financial integrity risk evaluation system that classifies user-generated content for scam and fraud signals. The key design decision was separating the policy layer from the inference engine â€” violation definitions, severity logic, and enforcement rules are all governed independently from the prompts. I then built three prompt versions with increasing recall bias and evaluated them on both clean and adversarial drift data. v1 missed 36 high-severity violations on drift. v3 missed zero."

**"Why recall over precision?"**  
"In safety systems, the cost of a false negative â€” missing a real violation â€” is much higher than a false positive. A missed money mule recruitment post could result in real financial harm to users. A false positive results in an unnecessary escalation review. The asymmetry is clear, so recall is the primary metric."

**"How would you extend this to production?"**  
"Four things: (1) Replace synthetic data with human-labeled production samples, (2) Add a confidence threshold to route borderline cases to human review queues, (3) Build a feedback loop where reviewer decisions update the gold dataset, and (4) Add multilingual support as language drift is much more severe across languages."

**"What was your biggest challenge?"**  
"v1 used `.format()` to inject content into prompt templates. The JSON output schema inside the prompt â€” with its curly braces â€” was being interpreted as Python format variables. It crashed silently and took a full debugging session to find. The fix was escaping all JSON examples in prompt files with double braces. It reinforced that prompt files are code artifacts and need the same rigor."

---

## ğŸ—“ï¸ Project Timeline

| Day | Focus | Deliverables |
|---|---|---|
| 1 | Foundation | Repo scaffold, config, schema, Streamlit placeholder |
| 2 | Policy & Taxonomy | reason_codes.json, policy.md, severity_rubric.md |
| 3 | Dataset Construction | 300 gold cases, 150 drift cases, validation assertions |
| 4 | Prompt Engineering | v1/v2/v3 prompts, LLM client, agent wiring |
| 5 | Evaluation Engine | Batch evaluator, metrics logger, full gold eval |
| 6 | Drift Evaluation | Drift eval, gold vs drift comparison, recall drop analysis |
| 7 | Dashboard | 4-tab Streamlit â€” metrics, drift monitor, taxonomy, live tester |
| 8 | README & Pipeline | Documentation, Dockerfile, clean run_pipeline.ipynb |

---

## ğŸ—‚ï¸ Project Structure
```
LLM-risk-agent/
â”œâ”€â”€ app.py                    # Streamlit dashboard
â”œâ”€â”€ config.py                 # Environment-controlled settings
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile                # Container deployment
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ architecture.html     # Interactive production architecture diagram
â”œâ”€â”€ policy/
â”‚   â”œâ”€â”€ policy.md
â”‚   â”œâ”€â”€ reason_codes.json
â”‚   â””â”€â”€ severity_rubric.md
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ v1_baseline.txt
â”‚   â”œâ”€â”€ v2_hierarchical.txt
â”‚   â””â”€â”€ v3_high_recall.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gold_cases.jsonl
â”‚   â””â”€â”€ drift_cases.jsonl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ schema.py
â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ metrics_logger.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ eval_runs/
â”‚       â””â”€â”€ eval_log.jsonl
â””â”€â”€ .streamlit/
    â””â”€â”€ secrets.toml.example
```

---

## ğŸš€ How to Run Locally
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export ANTHROPIC_API_KEY=your-key-here

# Launch dashboard
streamlit run app.py
```

---

## ğŸ³ Docker Deployment
```bash
# Build image
docker build -t llm-risk-agent .

# Run container
docker run -p 8501:8501 \
  -e ANTHROPIC_API_KEY=your-key-here \
  -e LLM_PROVIDER=anthropic \
  -e LLM_MODEL=claude-haiku-4-5-20251001 \
  llm-risk-agent
```

Then open: http://localhost:8501

---

## âš™ï¸ Environment Variables

| Variable | Description |
|---|---|
| LLM_PROVIDER | `anthropic` or `openai` |
| LLM_MODEL | model identifier string |
| ANTHROPIC_API_KEY | required if provider=anthropic |
| OPENAI_API_KEY | required if provider=openai |

---

## ğŸ”— Additional Resources

- [Live Dashboard](https://llm-risk-agent.streamlit.app) â€” Interactive metrics and live tester
- [Policy Framework](policy/policy.md) â€” Governance documentation
- [Severity Rubric](policy/severity_rubric.md) â€” Enforcement decision logic
- [Evaluation Log](logs/eval_runs/eval_log.jsonl) â€” Full audit trail

---

## ğŸ“ License

Â© 2026 SiDO Strategies. All rights reserved.

This repository is provided for portfolio and evaluation purposes only.  
No part of this software may be copied, modified, distributed, sublicensed, or used for commercial purposes without prior written permission from SiDO Strategies.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED.

Built by SWK â€¢ Feb 2026 â€¢ Platform Integrity & Risk Lead | MSc AI/ML (Distinction)  
[SiDO Strategies](https://sidosg.com) â€” AI Governance & Risk Advisory
